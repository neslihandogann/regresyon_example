# -*- coding: utf-8 -*-
"""vize.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dgo3pCvTI7egcl291WUrKQInjrtkN3TL

# Veri Seti Adı

**student-math**

linki:[student-math.csv](https://www.kaggle.com/code/manuri123/student-grade-prediction-with-ridge-and-lasso/data)

Problem ve Çözüm

Portekiz lise öğrencilerinin matematik final notunu tahmin etmek.
Portekizce lise öğrencilerinin matematik performanslarını etkileyen temel faktörleri belirlemek.
"""

import numpy as np# matematiksel işlemler (lineer cebir vs)
import pandas as pd# veriyi işlemede, CSV dosyası için (e.g. pd.read_csv)
import matplotlib.pyplot as plt
import seaborn as snst# veriyi görselleştirme
import warnings
# Sklearn  kütüphaneleri
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error,accuracy_score
from sklearn.model_selection import cross_val_score
#Cross-validation, makine öğrenmesi modelinin görmediği veriler üzerindeki performansını mümkün olduğunca objektif ve doğru bir şekilde değerlendirmek
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor#karar ağacları
from sklearn.svm import SVR
from sklearn.ensemble import RandomForestRegressor #rastgele orman
from sklearn.preprocessing import StandardScaler,MinMaxScaler,LabelEncoder

warnings.filterwarnings("ignore")

#veri setini ekleme işleme yapıldı
df = pd.read_csv("student-mat.csv")
df.info()#Bu yöntem, dizin türü ve sütunlar, boş olmayan değerler ve bellek kullanımı dahil olmak üzere bir DataFrame hakkında bilgi yazdırır.
df.head()#her zaman il beş değeri gösterir

df.isnull().sum()

df.shape #df’in satır ve sütun sayısını öğrenemek için kullanılır

import seaborn as sns
corr = df.corr()
sns.heatmap(corr, 
            xticklabels=corr.columns.values,
            yticklabels=corr.columns.values) 
# ısı haritası
#yorumlamak gerekirse G1,G2 ve G2,G3  arasında kuvvetli bi ilişki var

cmap = cmap=sns.diverging_palette(5, 250, as_cmap=True)
corr.style.background_gradient(cmap, axis=1)\
    .set_properties(**{'max-width': '80px', 'font-size': '10pt'})\
    .set_caption("Öğrenci Not Analiz Korelosyonu")\
    .set_precision(2)\
   
#burada daha detaylı korelasyon işlemini incelemek için detayli bir gösterim ile tasarlandı

#özellikler arasındaki ilişkiyi anlamak için bir korelasyon matrisi oluşturma
df.corr()

#describe() metodu sayısal verilere sahip olan sütunların max, min , std vb gibi istatiksel değerlerini döndürür.
df.describe()

"""

```
count - Boş olmayan değerlerin sayısı.
ortalama - Ortalama (ortalama) değer.
std - Standart sapma.
min - minimum değer.
%25 - %25 yüzdelik dilimi*.
%50 - %50 yüzdelik dilimi*.
%75 - %75 yüzdelik dilimi*.
max - maksimum değer.
```

"""

#verilen verilerde kadın ve erkeğe dağılımı
#shadow: Grafiğin altına gölge çizer. True ya da False değer alır.
#autopct: Grafiğin içine değerleri yüzdelik şekilde yazmamı sağlar.
total_count=df['sex'].value_counts()
plt.pie(x=total_count,colors=['lightskyblue','red'], labels=['Male','Female'],autopct='%1.1f%%',shadow=True)
plt.show()

#cinsiyete dayalı seyahat süresi ve G3 karşılaştırması
g=sns.boxplot(x='traveltime',y='G3',data=df,hue='sex')
g.set(xticklabels=['near','moderate','far','very far'])
plt.show()

#Babanın eğitimi ve final puanı
sns.boxplot(x='Fedu',y='G3',data=df)

#cinsiyete dayalı yaş grafiği
sns.countplot('age',hue='sex',data=df)

df.plot(x='G2', y='G3', style='o')  
# G2 G3 arasındaki ilişkiyi görebilmek için plotting çizimi yapıyoruz düzenli bi dağılım söz konusu biri artıyorsa diğeride artıyor

from datetime import datetime   # Mevcut 'age' özniteliğinden yeni bir 'dogumYili' özniteliği oluşturma
year=pd.datetime.now()
dogumYili=year.year-df['age']
df['dogumYili']=dogumYili
df

# veri normalleştirme
from sklearn import preprocessing

#G1 özniteliğini normalleştirmek istiyoruz
x = df[['G1']].values.astype(float)

#Normalleştirme için MinMax normalleştirme yöntemini kullanıyoruz.
min_max_scaler = preprocessing.MinMaxScaler()
x_scaled = min_max_scaler.fit_transform(x)
df['G1_new'] = pd.DataFrame(x_scaled)
df

# Kullanacağımız verilerimiz üzerinde biraz görselleştime yapalım.
import seaborn as sns
fig, axes = plt.subplots(2, 2, figsize=(16,12))
#seaborn.regplot() :Bu yöntem, verileri ve doğrusal bir regresyon model uyumunu çizmek için kullanılır. 
#swarmplot sürü grafiği çizmek için kullanılır
sns.regplot('G2', 'G3', data=df, ax=axes[0, 0]).set_title('G2 ve G3 notları')
sns.swarmplot('failures', 'G3', data=df, ax=axes[1, 0]).set_title('Başarısızlığın Başarı Notuna Etkisi')
sns.swarmplot('famrel', 'G3', data=df, ax=axes[0, 1]).set_title('Aile İlişkilerinin Başarı Notuna Etkisi')
sns.swarmplot('studytime', 'G3', data=df, ax=axes[1, 1]).set_title('Çalışma Zamanının Final Notuna Etkisi')
plt.tight_layout()
plt.show()

#annenin iş planı nı gösteren tablo
sns.countplot('Mjob',data=df)

#yüksek öğrenime devam etmeye dayalı olarak yaş ve  puan grafiği
sns.barplot(x='age',y='G3',data=df,hue='higher')

#İnternet kullanımına dayalı olarak çalışma süresi ile  puanın kutu grafiği
g=sns.boxplot(x='studytime',y='G3',hue='internet',data=df)
g.set(xticklabels=['very low','low','high','very high'])
plt.show()

#Makine öğrenmesinde kullanılan sınıflandırma modellerinin performansını değerlendirmek için hedef niteliğe ait tahminlerin ve gerçek değerlerin karşılaştırıldığı hata matrisi
# sıklıkla kullanılmaktadır.
""" 
Doğruya doğru demek (True Positive – TP) DOĞRU
Yanlışa yanlış demek (True Negative – TN) DOĞRU
Doğruya yanlış demek (False Positive – FP) YANLIŞ
Yanlışa doğru demek(False Negative – FN) YANLIŞ
"""
from sklearn.metrics import confusion_matrix, classification_report
##Tahmin puanlarından Alıcı Çalışma Özelliği Eğrisi Altındaki Hesaplama Alan
from sklearn.metrics import roc_curve, roc_auc_score
from sklearn import model_selection
#Eğitim için ilgili öznitlelik değerlerini seç
X = df.iloc[:,:-1].values
#l[:-1]-->l[başlangıç ​​: bitiş]--> varsayılan değer başlangıç=0 bitiş=-1
#iloc ta satır(row) ya da kolonu(column) indexlerine bagli olarak secer
Y = df.iloc[:, ].values
X
Y

X[:,3]

# Kategorik verileri kodlama yani label encoder işlemi ile char tipindeki karekterleri 0 ve 1 lere dönüştürme işlemi
from sklearn.preprocessing import LabelEncoder
labelencoder = LabelEncoder()
X[:, 1] = labelencoder.fit_transform(X[:, 1])#dönüştürme işlemi
X[:, 1]   #cinsiyet değerlerini char biçiminden çıkartıp algoritmanın anlayabilceği 0 ve 1 lere dönüştürdük- 0=F / 1=M

# Kategorik verileri kodlama yani label encoder işlemi ile char tipindeki karekterleri 0 ve 1 lere dönüştürme işlemi
from sklearn.preprocessing import LabelEncoder
labelencoder = LabelEncoder()
X[:, 5] = labelencoder.fit_transform(X[:, 5])
X[:, 5]  # ebeveynlerin birlikte yaşama durumu Ayrı olduklarında 0 birlikte olduklarında 1

from sklearn.metrics import confusion_matrix, classification_report
from sklearn.metrics import roc_curve, roc_auc_score
from sklearn import model_selection
#Eğitim için ilgili öznitlelik değerlerini seç
X = df.iloc[:, 30:33] 
#Sınıflandırma öznitelik değerlerini seç
Y = df.iloc[:, 30]

X

"""# Modeli Eğitip Tahmin Ettirme """

#veri seti modeli eğitimi için gerekli olan metodaları işledik
from sklearn.model_selection import train_test_split  
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)

from sklearn.linear_model import LinearRegression
model = LinearRegression()
model.fit(X_train, y_train)

# Test seti sonuçlarını tahmin etme
y_pred = model.predict(X_test)

df2 = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})  #gerçek değil ile tahmin edilen değeri karşılaştırma
df2

#yalnızca ana özellikleri ayıklama işlemi yapılacak amacı aşağıda bazı algoritma modelleri ile gereken işlemleri daha kısa süede ihtiyacıı olanı en kısa yoldan bulmak için
df_ozellik=df[['G1','G2','Medu','Fedu','studytime']]
df_ozellik.head()
df_label=df[['G3']]

#değerleri bölmek için numpy türünde diziler olarak alma
X=df_ozellik.values
y=df_label.values

#değerleri bölmek için numpy türünde diziler olarak alma
X=df_ozellik.values
y=df_label.values

#x ve y değişken değerlerini bölme
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=42)

#çeşitli modellerde regresyon gerçekleştirme ve skorları saklama
#aşağıda çeşitli model işlevleri yapılıp sonuçlara bakarak modeller arasında karşılaştırma yapabilirsiniz
scores={}
def classifier():#sınıflandırıcı fonksiyonu
    dict_models={
        'Linear Regression':LinearRegression(),
        'Support Vector Machine':SVR(kernel='linear',degree=1),

       """
       Support Vector Machine (Destek Vektör Makinesi desek nasıl durur bilmiyorum) sınıflandırma için kullanılan yöntemlerden birisidir. 
       Temel olarak iki sınıfı bir doğru veya düzlem ile birbirinden ayırmaya çalışır. Bu ayırmayı da sınırdaki elemanlara göre yapar.
       """

        'Decision Tree':DecisionTreeRegressor(criterion='mae'),

        """ 
        Bir karar ağacı, çok sayıda kayıt içeren bir veri kümesini, bir dizi karar kurallarının ayrıntılarını daha küçük kümelere bölmek için
         kullanılan bir yapıdır. Yani basit karar verme usulü uygulanarak, büyük hayvanlardaki kayıtlar, çok küçük kayıt yapısına bölerek kullanılan 
         bir yapıdır. sıklıkla kullanılan regresyon modelidir.
         """
        """
         Rastgele ormanlar veya rastgele karar ormanları, sınıflandırma, regresyon ve diğer görevler için, eğitim aşamasında çok sayıda karar ağacı
         oluşturarak problemin tipine göre sınıf veya sayı tahmini yapan bir toplu öğrenme yöntemidir. 
        """
        'Random Forest':RandomForestRegressor(n_estimators=150,criterion='mse',verbose=0)

     

    }
    X_train.shape
    y_train.shape

    """ mse ->mean square error, -türkçeye hataların karelerinin ortalaması olarak çevrilebilir- çok basit şekilde sizin regresyon doğrunuzla data 
    noktalarının aralarındaki uzaklığın karesini alır ve kaç tane nokta varsa o sayıya böler.
      
     mae ->Ortalama mutlak hata, mutlak hata değerinin toplamını alır, hata terimlerinin toplamının daha doğrudan bir temsilidir.
     
     rmse-> Ortalama kare sapması veya ortalama karekök hatası, bir model veya tahmin edici tarafından tahmin edilen değerler ile gözlemlenen
     değerler arasındaki farkların sıklıkla kullanılan bir ölçüsüdür.
    
    """
    
    for key,value in dict_models.items():
        regression=value.fit(X_train,y_train)
        score=cross_val_score(regression,X,y,scoring='neg_mean_squared_error')
        score=np.sqrt(-score.mean())
        scores[key]=score
        print(
            f'Model Name: {key},RMSE score: {(score.mean())}')

classifier()

#değerleri ölçeklendirme (rmse'yi değiştirmese de)
""" MinMax Scaling, verinin 0 ile 1 arasında değerler aldığı bir durumdur. Burada dağılım, verinin dağılımı ile benzerdir. Burada ‘outlier’
 denilen dışta kalan verilere karşı hassasiyet durumu vardı"""
from sklearn.preprocessing import MinMaxScaler
sc_s=MinMaxScaler()
X_train=sc_s.fit_transform(X_train)
X_test=sc_s.transform(X_test)

classifier()

# lineer model import edildi
from sklearn import linear_model
from sklearn.metrics import mean_squared_error
# lasso ve ridge model nesneleri oluşturuldu
lasso = linear_model.Lasso()
ridge = linear_model.Ridge()
# modeli eğitme işlemi
lasso.fit(X, y)
ridge.fit(X, y)
# katsayılar ,mse hatası,ve puanlar ekrana basılacak
print("lasso score:", lasso.score(X, y))
print("ridge score:",ridge.score(X, y))
print("lasso MSE:", mean_squared_error(y, lasso.predict(X)))
print("ridge MSE:", mean_squared_error(y, ridge.predict(X)))
print("lasso coef:", lasso.coef_)
print("ridge coef:", ridge.coef_)

# Gerekli içe aktarmaları yapılacak, verileri eğitim ve test kümelerine ayrılacak ve bir dizi parametre seçilecek
from sklearn.model_selection import train_test_split
from sklearn.model_selection import GridSearchCV
import warnings
warnings.filterwarnings("ignore")

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=101)
parametereler = {'alpha': np.concatenate((np.arange(0.1,2,0.1), np.arange(2, 5, 0.5), np.arange(5, 25, 1)))}

linear = linear_model.LinearRegression()
lasso = linear_model.Lasso()
ridge = linear_model.Ridge()
gridlasso = GridSearchCV(lasso, parametereler, scoring ='r2')
gridridge = GridSearchCV(ridge, parametereler, scoring ='r2')

# Modelleri sığdırın ve en iyi parametreleri, R-kare puanlarını, MSE'yi ve katsayıları yazdırın
gridlasso.fit(X_train, y_train)
gridridge.fit(X_train, y_train)
linear.fit(X_train, y_train)
print("ridge en iyi parametreler:", gridridge.best_params_)
print("lasso en iyi parametreler:", gridlasso.best_params_)
print("ridge puanı:", gridridge.score(X_test, y_test))
print("lasso puanı:", gridlasso.score(X_test, y_test))
print("linear puanı:", linear.score(X_test, y_test))
print("ridge MSE:", mean_squared_error(y_test, gridridge.predict(X_test)))
print("lasso MSE:", mean_squared_error(y_test, gridlasso.predict(X_test)))
print("linear MSE:", mean_squared_error(y_test, linear.predict(X_test)))
print("ridge en iyi tahmin edici katsayısı:", gridridge.best_estimator_.coef_)
print("lasso en iyi tahmin edici katsayısı:", gridlasso.best_estimator_.coef_)
print("linear katsayısı:", linear.coef_)

import matplotlib.pyplot as plt
import numpy as np

from sklearn.datasets import make_regression
from sklearn.linear_model import Ridge
from sklearn.metrics import mean_squared_error

df = Ridge()

X, y, w= make_regression(
    n_samples=10, n_features=10, coef=True, random_state=42, bias=3.5
)

#Bias nöronu aktivasyon fonksiyonunu grafik üzerinde sola veya sağa kaydırmayı mümkün kılar. 

coefs = []#katsayı dizileri
errors =[]#hata dizileri

alphas = np.logspace(-6, 6, 200)
#Bir günlük ölçeğinde eşit aralıklarla sayıları döndürün.

# Modeli farklı düzenleme güçleri ile eğitilir
for a in alphas:
    df.set_params(alpha=a)
    df.fit(X, y)
    coefs.append(df.coef_)
    errors.append(mean_squared_error(df.coef_, w))

# Sonuçları gösterme
plt.figure(figsize=(20, 6))

plt.subplot(121)
# gca() işlevi , verilen args anahtar kelimesiyle eşleşen mevcut şekilde mevcut Axes örneğini almak veya bir tane oluşturmak için kullanılır.
ax = plt.gca()
ax.plot(alphas, coefs)
ax.set_xscale("log")#dağınık dağılım
plt.xlabel("log")
plt.ylabel("weights")
plt.title(" ridge katsayıları")
plt.axis("tight")

plt.subplot(122)
ax = plt.gca()
ax.plot(alphas, errors)
#logaritmik ölçeklendirme işlemi yapılır ,değerler logoritmik düzeyde akatarılır
ax.set_xscale("log")#dağınık dağılım
plt.xlabel("log")
plt.ylabel("error")
plt.title(" katsayı hatası")
plt.axis("tight")#çakışmayı engeller